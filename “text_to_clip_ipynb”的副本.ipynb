{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thd2020/text-2-clip/blob/main/%E2%80%9Ctext_to_clip_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOGyKljANwOF"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n",
        "# For security purposes, please check the contents of collect_env.py before running it.\n",
        "!python collect_env.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ey84X1fkdyIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1Q9hMAwgcWg"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update && apt-get install ffmpeg libsm6 libxext6  -y\n",
        "!pip install --upgrade torchvision torchaudio\n",
        "!pip install pytorch-pretrained-biggan\n",
        "!pip install huggingface_hub\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install sacremoses\n",
        "!pip install tacotron2\n",
        "!pip install modelscope==1.8.4\n",
        "!pip install xformers==0.0.20\n",
        "!pip install open_clip_torch>=2.0.2\n",
        "!pip install opencv-python-headless\n",
        "!pip install opencv-python\n",
        "!pip install einops>=0.4\n",
        "!pip install rotary-embedding-torch\n",
        "!pip install fairscale\n",
        "!pip install scipy\n",
        "!pip install imageio\n",
        "!pip install pytorch-lightning\n",
        "!pip install torchsde"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision==0.16.1+cu121 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "XXU-M1N8LjhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchaudio==2.1.1+cu121 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "sD_dUoHcNAeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch\n",
        "!pip uninstall torch\n",
        "!pip install torch==2.1.1+cu121 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "yW8LMJE7Nxkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoCsSBYfe1IS"
      },
      "outputs": [],
      "source": [
        "# 导入所需的库\n",
        "import torch\n",
        "import torch.hub\n",
        "import torchvision\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import cv2\n",
        "import moviepy.editor as mpy\n",
        "import os\n",
        "import requests, json\n",
        "import nltk.stem.wordnet\n",
        "import open_clip\n",
        "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
        "                                       save_as_images, display_in_terminal, convert_to_images)\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tacotron2.text import text_to_sequence\n",
        "from modelscope.pipelines import pipeline\n",
        "from modelscope.outputs import OutputKeys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FPmObmz3ky5"
      },
      "outputs": [],
      "source": [
        "!python3 -m nltk.downloader wordnet\n",
        "!unzip /root/nltk_data/corpora/wordnet.zip -d /root/nltk_data/corpora/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isZCvGHOfKQo"
      },
      "outputs": [],
      "source": [
        "# 定义使用自然语言处理（NLP）模型提取文本中的关键词和类别的函数\n",
        "def extract_keywords_and_category_with_nlp(text):\n",
        "  # 加载预训练的BERT模型\n",
        "  model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-cased')\n",
        "  # 加载预训练的BERT分词器\n",
        "  tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')\n",
        "  # 设置模型为评估模式\n",
        "  model.eval()\n",
        "  # 将文本转换为张量\n",
        "  tokens = tokenizer.encode(text, add_special_tokens=True)\n",
        "  tokens = torch.LongTensor(tokens).unsqueeze(0)\n",
        "  # 创建一个空的关键词列表\n",
        "  keywords = []\n",
        "  # 创建一个空的类别列表\n",
        "  categories = []\n",
        "  # 对每个单词进行处理\n",
        "  for i in range(len(tokens[0])):\n",
        "    # 获取单词的文本\n",
        "    word = tokenizer.decode(tokens[0][i])\n",
        "    # 如果单词是一个名词或形容词，且不是一个停用词，那么将其视为一个关键词\n",
        "    if word in imagenet:\n",
        "      # 将单词添加到关键词列表中\n",
        "      keywords.append(word)\n",
        "  return keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeBIJcVGfHDw"
      },
      "outputs": [],
      "source": [
        "# 定义使用BigGAN生成图像的函数\n",
        "def generate_image_with_biggan(text):\n",
        "  images=[]\n",
        "  # 加载预训练的BigGAN模型\n",
        "  model = BigGAN.from_pretrained('biggan-deep-512')\n",
        "  # 设置模型为评估模式\n",
        "  model.eval()\n",
        "  # 使用自然语言处理（NLP）模型提取文本中的关键词\n",
        "  keywords = extract_keywords_and_category_with_nlp(text)\n",
        "\n",
        "  # Prepare a input\n",
        "  truncation = 0.4\n",
        "  class_vector = one_hot_from_names(keywords, batch_size=len(keywords))\n",
        "  print(\"keywords = \", keywords)\n",
        "  noise_vector = truncated_noise_sample(truncation=truncation, batch_size=len(keywords))\n",
        "\n",
        "  # All in tensors\n",
        "  noise_vector = torch.from_numpy(noise_vector)\n",
        "  class_vector = torch.from_numpy(class_vector)\n",
        "\n",
        "  # If you have a GPU, put everything on cuda\n",
        "  noise_vector = noise_vector.to('cuda')\n",
        "  class_vector = class_vector.to('cuda')\n",
        "  model.to('cuda')\n",
        "\n",
        "  # Generate an image\n",
        "  with torch.no_grad():\n",
        "      output = model(noise_vector, class_vector, truncation)\n",
        "\n",
        "  # If you have a GPU put back on CPU\n",
        "  output = output.to('cpu')\n",
        "  save_as_images(output)\n",
        "  output = convert_to_images(output)\n",
        "  images=[]\n",
        "  for image in output:\n",
        "    images.append(cv2.cvtColor(np.asarray(image),cv2.COLOR_RGB2BGR))\n",
        "\n",
        "  # 返回生成的图像\n",
        "  return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpqH_DlbfSPz"
      },
      "outputs": [],
      "source": [
        "# 定义使用Tacotron 2生成音频的函数\n",
        "def generate_audio_with_tacotron2(text):\n",
        "  # 加载预训练的Tacotron 2模型\n",
        "  model = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_tacotron2', pretrained=True, force_reload=True)\n",
        "  # 设置模型为评估模式\n",
        "  model.eval()\n",
        "  # 将模型移动到CUDA设备上\n",
        "  model = model.to('cuda')\n",
        "  # 加载预训练的WaveGlow模型\n",
        "  waveglow = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_waveglow', pretrained=True, force_reload=True)\n",
        "  # 设置模型为评估模式\n",
        "  waveglow.eval()\n",
        "  # 将模型移动到CUDA设备上\n",
        "  waveglow = waveglow.to('cuda')\n",
        "  # 将文本转换为张量\n",
        "  text = torch.LongTensor(text_to_sequence(text, ['english_cleaners'])).unsqueeze(0).to('cuda')\n",
        "  # 使用Tacotron 2模型生成音频的梅尔频谱\n",
        "  with torch.no_grad():\n",
        "    mel, _, _ = model.infer(text)\n",
        "  # 使用WaveGlow模型生成音频的波形\n",
        "  with torch.no_grad():\n",
        "    audio = waveglow.infer(mel)\n",
        "  # 将音频转换为numpy数组\n",
        "  audio = audio[0].detach().cpu().numpy()\n",
        "  # 返回生成的音频\n",
        "  return audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QWjJlrMff9A"
      },
      "outputs": [],
      "source": [
        "# 定义使用Video GPT生成视频的函数\n",
        "def generate_video_with_videogpt(image):\n",
        "  pipe = pipeline(task='image-to-video', model='damo/Image-to-Video', model_revision='v1.1.0')\n",
        "  # IMG_PATH: your image path (url or local file)\n",
        "  output_video_path = pipe(image, output_video='./output_0.mp4')[OutputKeys.OUTPUT_VIDEO]\n",
        "  print(output_video_path)\n",
        "  # 返回生成的视频\n",
        "  return video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A780gSVGfhx1"
      },
      "outputs": [],
      "source": [
        "# 定义文本转视频的函数\n",
        "def text_to_video(text):\n",
        "  # 将文本分割成句子\n",
        "  sentences = text.split(\".\")\n",
        "  # 创建一个空的视频列表\n",
        "  video_list = []\n",
        "  # 对每个句子进行处理\n",
        "  for sentence in sentences:\n",
        "    # 使用BigGAN生成图像\n",
        "    image = generate_image_with_biggan(sentence)\n",
        "    # 使用Tacotron 2生成音频\n",
        "    audio = generate_audio_with_tacotron2(sentence)\n",
        "    # 使用Video GPT生成视频\n",
        "    video = generate_video_with_videogpt(image, audio)\n",
        "    # 将视频添加到视频列表中\n",
        "    video_list.append(video)\n",
        "  # 将视频列表拼接成一个完整的视频\n",
        "  final_video = mpy.concatenate_videoclips(video_list)\n",
        "  # 返回最终的视频\n",
        "  return final_video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H1OuczNCB8g"
      },
      "outputs": [],
      "source": [
        "# 定义要打开的文本文件的路径\n",
        "file_path = \"drive/MyDrive/imagenet_classes.txt\"\n",
        "\n",
        "# 以读取模式打开文本文件\n",
        "with open(file_path, \"r\") as file:\n",
        "    # 读取文本文件的内容\n",
        "    content = file.read()\n",
        "    imagenet = content.replace(\"\\n\", \",\").replace(\"\\n\",\"\").replace(\" \",\"\").split(\",\")\n",
        "    imagenet = [x.replace(\"\\n\",\"\") for x in imagenet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m0n1S2-fnUE"
      },
      "outputs": [],
      "source": [
        "erer = \"tiger lion\"\n",
        "\n",
        "\n",
        "images = generate_image_with_biggan(erer)\n",
        "\n",
        "for image in images:\n",
        "  cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_video_with_videogpt(\"output_0.png\")"
      ],
      "metadata": {
        "id": "d7dAjf_LhlK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lr3852LHNn1"
      },
      "outputs": [],
      "source": [
        "# 定义一个示例文本\n",
        "text = \"tiger mushroom bee.\"\n",
        "\n",
        "# 调用文本转视频的函数\n",
        "video = text_to_video(text)\n",
        "\n",
        "# 保存视频到本地\n",
        "video.write_videofile(\"text_to_video.mp4\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}