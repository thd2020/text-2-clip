{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thd2020/text-2-clip/blob/main/text_to_clip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOGyKljANwOF",
        "outputId": "95493061-1955-4a96-90c5-69c70d29d567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-09 07:34:04--  https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21864 (21K) [text/plain]\n",
            "Saving to: ‘collect_env.py’\n",
            "\n",
            "collect_env.py      100%[===================>]  21.35K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-09 07:34:05 (126 MB/s) - ‘collect_env.py’ saved [21864/21864]\n",
            "\n",
            "Collecting environment information...\n",
            "PyTorch version: 2.1.0+cu118\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 11.8\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 22.04.2 LTS (x86_64)\n",
            "GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Clang version: 14.0.0-1ubuntu1.1\n",
            "CMake version: version 3.27.7\n",
            "Libc version: glibc-2.35\n",
            "\n",
            "Python version: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] (64-bit runtime)\n",
            "Python platform: Linux-5.15.120+-x86_64-with-glibc2.35\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: 11.8.89\n",
            "CUDA_MODULE_LOADING set to: LAZY\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 525.105.17\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "Is XNNPACK available: True\n",
            "\n",
            "CPU:\n",
            "Architecture:                    x86_64\n",
            "CPU op-mode(s):                  32-bit, 64-bit\n",
            "Address sizes:                   46 bits physical, 48 bits virtual\n",
            "Byte Order:                      Little Endian\n",
            "CPU(s):                          2\n",
            "On-line CPU(s) list:             0,1\n",
            "Vendor ID:                       GenuineIntel\n",
            "Model name:                      Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "CPU family:                      6\n",
            "Model:                           85\n",
            "Thread(s) per core:              2\n",
            "Core(s) per socket:              1\n",
            "Socket(s):                       1\n",
            "Stepping:                        3\n",
            "BogoMIPS:                        4000.30\n",
            "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "Hypervisor vendor:               KVM\n",
            "Virtualization type:             full\n",
            "L1d cache:                       32 KiB (1 instance)\n",
            "L1i cache:                       32 KiB (1 instance)\n",
            "L2 cache:                        1 MiB (1 instance)\n",
            "L3 cache:                        38.5 MiB (1 instance)\n",
            "NUMA node(s):                    1\n",
            "NUMA node0 CPU(s):               0,1\n",
            "Vulnerability Itlb multihit:     Not affected\n",
            "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
            "Vulnerability Mds:               Vulnerable; SMT Host state unknown\n",
            "Vulnerability Meltdown:          Vulnerable\n",
            "Vulnerability Mmio stale data:   Vulnerable\n",
            "Vulnerability Retbleed:          Vulnerable\n",
            "Vulnerability Spec store bypass: Vulnerable\n",
            "Vulnerability Spectre v1:        Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers\n",
            "Vulnerability Spectre v2:        Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBRS: Not affected\n",
            "Vulnerability Srbds:             Not affected\n",
            "Vulnerability Tsx async abort:   Vulnerable\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.23.5\n",
            "[pip3] torch==2.1.0+cu118\n",
            "[pip3] torchaudio==2.1.0+cu118\n",
            "[pip3] torchdata==0.7.0\n",
            "[pip3] torchsummary==1.5.1\n",
            "[pip3] torchtext==0.16.0\n",
            "[pip3] torchvision==0.16.0+cu118\n",
            "[pip3] triton==2.1.0\n",
            "[conda] Could not collect\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n",
        "# For security purposes, please check the contents of collect_env.py before running it.\n",
        "!python collect_env.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1Q9hMAwgcWg",
        "outputId": "97dd4556-97aa-466a-919e-7710f421dbc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-biggan\n",
            "  Downloading pytorch_pretrained_biggan-0.1.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (1.23.5)\n",
            "Collecting boto3 (from pytorch-pretrained-biggan)\n",
            "  Downloading boto3-1.28.82-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-biggan) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (2.1.0)\n",
            "Collecting botocore<1.32.0,>=1.31.82 (from boto3->pytorch-pretrained-biggan)\n",
            "  Downloading botocore-1.31.82-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-pretrained-biggan)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3->pytorch-pretrained-biggan)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-biggan) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.82->boto3->pytorch-pretrained-biggan) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-biggan) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-biggan) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.82->boto3->pytorch-pretrained-biggan) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-biggan\n",
            "Successfully installed boto3-1.28.82 botocore-1.31.82 jmespath-1.0.1 pytorch-pretrained-biggan-0.1.1 s3transfer-0.7.0\n",
            "\u001b[33mWARNING: Skipping huggingface_hub as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n",
            "Installing collected packages: huggingface_hub\n",
            "Successfully installed huggingface_hub-0.19.0\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.0\n",
            "    Uninstalling huggingface-hub-0.19.0:\n",
            "      Successfully uninstalled huggingface-hub-0.19.0\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-pretrained-biggan\n",
        "!pip uninstall huggingface_hub\n",
        "!pip install huggingface_hub\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoCsSBYfe1IS"
      },
      "outputs": [],
      "source": [
        "# 导入所需的库\n",
        "import torch\n",
        "import torch.hub\n",
        "import torchvision\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import cv2\n",
        "import moviepy.editor as mpy\n",
        "import os\n",
        "import requests, json\n",
        "import nltk.stem.wordnet\n",
        "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
        "                                       save_as_images, display_in_terminal, convert_to_images)\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FPmObmz3ky5",
        "outputId": "b95072e0-cdf3-4c50-a744-95c65251efdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "Archive:  /root/nltk_data/corpora/wordnet.zip\n",
            "   creating: /root/nltk_data/corpora/wordnet/\n",
            "  inflating: /root/nltk_data/corpora/wordnet/lexnames  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/data.verb  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/index.adv  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/adv.exc  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/index.verb  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/cntlist.rev  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/data.adj  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/index.adj  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/LICENSE  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/citation.bib  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/noun.exc  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/verb.exc  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/README  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/index.sense  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/data.noun  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/data.adv  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/index.noun  \n",
            "  inflating: /root/nltk_data/corpora/wordnet/adj.exc  \n"
          ]
        }
      ],
      "source": [
        "!python3 -m nltk.downloader wordnet\n",
        "!unzip /root/nltk_data/corpora/wordnet.zip -d /root/nltk_data/corpora/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isZCvGHOfKQo"
      },
      "outputs": [],
      "source": [
        "# 定义使用自然语言处理（NLP）模型提取文本中的关键词和类别的函数\n",
        "def extract_keywords_and_category_with_nlp(text):\n",
        "  # 加载预训练的BERT模型\n",
        "  model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-cased')\n",
        "  # 加载预训练的BERT分词器\n",
        "  tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')\n",
        "  # 设置模型为评估模式\n",
        "  model.eval()\n",
        "  # 将文本转换为张量\n",
        "  tokens = tokenizer.encode(text, add_special_tokens=True)\n",
        "  tokens = torch.LongTensor(tokens).unsqueeze(0)\n",
        "  # 创建一个空的关键词列表\n",
        "  keywords = []\n",
        "  # 创建一个空的类别列表\n",
        "  categories = []\n",
        "  # 对每个单词进行处理\n",
        "  for i in range(len(tokens[0])):\n",
        "    # 获取单词的文本\n",
        "    word = tokenizer.decode(tokens[0][i])\n",
        "    print(word)\n",
        "    # 如果单词是一个名词或形容词，且不是一个停用词，那么将其视为一个关键词\n",
        "    if word in imagenet:\n",
        "      # 将单词添加到关键词列表中\n",
        "      keywords.append(word)\n",
        "  return keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeBIJcVGfHDw"
      },
      "outputs": [],
      "source": [
        "# 定义使用BigGAN生成图像的函数\n",
        "def generate_image_with_biggan(text):\n",
        "  images=[]\n",
        "  # 加载预训练的BigGAN模型\n",
        "  model = BigGAN.from_pretrained('biggan-deep-512')\n",
        "  # 设置模型为评估模式\n",
        "  model.eval()\n",
        "  # 使用自然语言处理（NLP）模型提取文本中的关键词\n",
        "  keywords = extract_keywords_and_category_with_nlp(text)\n",
        "\n",
        "  # Prepare a input\n",
        "  truncation = 0.4\n",
        "  print(\"keywords= \", keywords)\n",
        "  class_vector = one_hot_from_names(keywords, batch_size=5)\n",
        "  print(\"keywords = \", keywords, \", class_vertor = \", class_vector)\n",
        "  noise_vector = truncated_noise_sample(truncation=truncation, batch_size=5)\n",
        "\n",
        "  # All in tensors\n",
        "  noise_vector = torch.from_numpy(noise_vector)\n",
        "  class_vector = torch.from_numpy(class_vector)\n",
        "\n",
        "  # If you have a GPU, put everything on cuda\n",
        "  noise_vector = noise_vector.to('cuda')\n",
        "  class_vector = class_vector.to('cuda')\n",
        "  model.to('cuda')\n",
        "\n",
        "  # Generate an image\n",
        "  with torch.no_grad():\n",
        "      output = model(noise_vector, class_vector, truncation)\n",
        "\n",
        "  # If you have a GPU put back on CPU\n",
        "  output = output.to('cpu')\n",
        "\n",
        "  images = convert_to_images(output)\n",
        "\n",
        "  # 返回生成的图像\n",
        "  return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpqH_DlbfSPz"
      },
      "outputs": [],
      "source": [
        "# 定义使用Tacotron 2生成音频的函数\n",
        "def generate_audio_with_tacotron2(text):\n",
        "  # 加载预训练的Tacotron 2模型\n",
        "  model = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_tacotron2', pretrained=True)\n",
        "  # 设置模型为评估模式\n",
        "  model.eval()\n",
        "  # 加载预训练的WaveGlow模型\n",
        "  waveglow = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_waveglow', pretrained=True)\n",
        "  # 设置模型为评估模式\n",
        "  waveglow.eval()\n",
        "  # 将文本转换为张量\n",
        "  text = torch.LongTensor(model.text_to_sequence(text, ['english_cleaners']))\n",
        "  # 使用Tacotron 2模型生成音频的梅尔频谱\n",
        "  with torch.no_grad():\n",
        "    mel, _, _ = model.infer(text.unsqueeze(0))\n",
        "  # 使用WaveGlow模型生成音频的波形\n",
        "  with torch.no_grad():\n",
        "    audio = waveglow.infer(mel)\n",
        "  # 将音频转换为numpy数组\n",
        "  audio = audio[0].detach().numpy()\n",
        "  # 返回生成的音频\n",
        "  return audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QWjJlrMff9A"
      },
      "outputs": [],
      "source": [
        "# 定义使用Video GPT生成视频的函数\n",
        "def generate_video_with_videogpt(image, audio):\n",
        "  # 加载预训练的Video GPT模型\n",
        "  model = torch.hub.load('williamFalcon/pytorch-video-gan', 'videogan', pretrained=True)\n",
        "  # 设置模型为评估模式\n",
        "  model.eval()\n",
        "  # 将图像和音频转换为张量\n",
        "  images = torch.from_numpy(images).permute(0, 3, 1, 2)\n",
        "  audio = torch.from_numpy(audio).unsqueeze(0)\n",
        "  # 使用Video GPT模型生成视频\n",
        "  with torch.no_grad():\n",
        "    video = model(images, audio)\n",
        "  # 将视频转换为numpy数组\n",
        "  video = video[0].permute(1, 2, 3, 0).detach().numpy()\n",
        "  # 返回生成的视频\n",
        "  return video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A780gSVGfhx1"
      },
      "outputs": [],
      "source": [
        "# 定义文本转视频的函数\n",
        "def text_to_video(text):\n",
        "  # 将文本分割成句子\n",
        "  sentences = text.split(\".\")\n",
        "  # 创建一个空的视频列表\n",
        "  video_list = []\n",
        "  # 对每个句子进行处理\n",
        "  for sentence in sentences:\n",
        "    # 使用BigGAN生成图像\n",
        "    image = generate_image_with_biggan(sentence)\n",
        "    # 使用Tacotron 2生成音频\n",
        "    audio = generate_audio_with_tacotron2(sentence)\n",
        "    # 使用Video GPT生成视频\n",
        "    video = generate_video_with_videogpt(image, audio)\n",
        "    # 将视频添加到视频列表中\n",
        "    video_list.append(video)\n",
        "  # 将视频列表拼接成一个完整的视频\n",
        "  final_video = mpy.concatenate_videoclips(video_list)\n",
        "  # 返回最终的视频\n",
        "  return final_video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H1OuczNCB8g"
      },
      "outputs": [],
      "source": [
        "# 定义要打开的文本文件的路径\n",
        "file_path = \"imagenet_classes.txt\"\n",
        "\n",
        "# 以读取模式打开文本文件\n",
        "with open(file_path, \"r\") as file:\n",
        "    # 读取文本文件的内容\n",
        "    content = file.read()\n",
        "    imagenet = content.replace(\"\\n\", \",\").replace(\"\\n\",\"\").replace(\" \",\"\").split(\",\")\n",
        "    imagenet = [x.replace(\"\\n\",\"\") for x in imagenet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "8m0n1S2-fnUE",
        "outputId": "fad4f5bb-fbf2-4aa8-93ef-3c675e260bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\n",
            "min\n",
            "##k\n",
            "fly\n",
            "bee\n",
            "pu\n",
            "##g\n",
            "ch\n",
            "##ow\n",
            "[SEP]\n",
            "keywords=  ['fly', 'bee']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-e8dcd0ed7318>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_image_with_biggan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-106-427ae84e9c5b>\u001b[0m in \u001b[0;36mgenerate_image_with_biggan\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mtruncation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keywords= \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mclass_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_from_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keywords = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\", class_vertor = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mnoise_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruncated_noise_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_pretrained_biggan/utils.py\u001b[0m in \u001b[0;36mone_hot_from_names\u001b[0;34m(class_name_or_list, batch_size)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGENET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossible_synsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mone_hot_from_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_pretrained_biggan/utils.py\u001b[0m in \u001b[0;36mone_hot_from_int\u001b[0;34m(int_or_list, batch_size)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mint_or_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint_or_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_or_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "erer = \"mink fly bee pug chow\"\n",
        "\n",
        "\n",
        "images = generate_image_with_biggan(erer)\n",
        "\n",
        "for image in images:\n",
        "  img = cv2.cvtColor(np.asarray(image),cv2.COLOR_RGB2BGR)\n",
        "  cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "3lr3852LHNn1",
        "outputId": "1b134398-6854-4c17-fa57-459d2fe11338"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS]\n",
            "cat\n",
            "dog\n",
            "[SEP]\n",
            "keywords=  []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-489a21af6c5f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 调用文本转视频的函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 保存视频到本地\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-1cf6a1f79fcc>\u001b[0m in \u001b[0;36mtext_to_video\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 使用BigGAN生成图像\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_image_with_biggan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 使用Tacotron 2生成音频\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_audio_with_tacotron2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-803cefb23cb1>\u001b[0m in \u001b[0;36mgenerate_image_with_biggan\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mtruncation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keywords= \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mclass_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_from_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'soap bubble'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coffee'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mushroom'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keywords = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\", class_vertor = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mnoise_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruncated_noise_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_pretrained_biggan/utils.py\u001b[0m in \u001b[0;36mone_hot_from_names\u001b[0;34m(class_name_or_list, batch_size)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGENET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossible_synsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mone_hot_from_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_pretrained_biggan/utils.py\u001b[0m in \u001b[0;36mone_hot_from_int\u001b[0;34m(int_or_list, batch_size)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mint_or_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint_or_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_or_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 定义一个示例文本\n",
        "text = \"cat dog.\"\n",
        "\n",
        "# 调用文本转视频的函数\n",
        "video = text_to_video(text)\n",
        "\n",
        "# 保存视频到本地\n",
        "video.write_videofile(\"text_to_video.mp4\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMccd1Z+gokAK59hpABSAvu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}